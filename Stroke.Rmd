---
title: "Stroke Dataset"
author: "Hunter Blum, Ben Earnest, Andrew Pak Kim"
date: "4/7/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Dataset:

https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset

# Libraries
```{r}
library(tidyverse)
library(caret)
library(NeuralNetTools)
library(neuralnet)
library(nnet)
library(smotefamily)
library(unbalanced)
library(doParallel)
library(DataExplorer)

set.seed(123)
```

# Data
```{r}
Stroke <- read.csv("stroke.csv")
```

# Multicore Support - Need to have Java Installed that is the same bit as your CPU (Probably 64)
```{r}
registerDoParallel()
getDoParWorkers()
```

# Cleaning the Data

The data is pretty clean after running this code. All variables are the correct type after running it. The only variable missing data is BMI, which only has 200/5100 observations missing. 

## Structure
```{r}
str(Stroke)

#Get rid of one other observation in gender
Stroke <- Stroke %>% filter(gender!="Other")

#Fix specific variables
Stroke$hypertension <- as.factor(Stroke$hypertension)
Stroke$heart_disease <- as.factor(Stroke$heart_disease)
Stroke$bmi <- as.numeric(Stroke$bmi)
Stroke$stroke <- as.factor(Stroke$stroke)

#Make all character variables into factors
Stroke[sapply(Stroke, is.character)] <- lapply(Stroke[sapply(Stroke, is.character)], as.factor)


str(Stroke)

#Rename Factors for Easier Understanding
levels(Stroke$hypertension) <- c("No", "Yes")
levels(Stroke$heart_disease) <- c("No", "Yes")
levels(Stroke$stroke) <- c("No", "Yes")

#Get Rid of id
Stroke$id <- NULL
```
## NAs
```{r}
Stroke %>% 
  select(everything()) %>% 
  summarise_all(funs(sum(is.na(.))))
#Just 201 missing observations in bmi 

#We'll just delete the NAs for now
Stroke_clean <- na.omit(Stroke)
```



# Exploratory Data Analysis

Our target feature is stroke, where 1 indicates that a stroke occurred. For any binary attributes 1 is always the variable occurred (eg. 1 for heart disease means the patient had heart disease). 

## Dataset Overview
```{r}
summary(Stroke_clean)
head(Stroke_clean)
```


## Variable by Stroke
### Make Functions
```{r}
#Categorical
Cat_eda <- function(x, y) {
  p1 <- ggplot(Stroke_clean, aes(x={{x}})) +
    geom_bar(aes(fill=stroke) , color = "black") +
    ggtitle(paste0("Stroke with Respect to ", y)) +
    xlab(y) + ylab("Count")

  p2 <- ggplot(Stroke_clean, aes(x={{x}})) +
    geom_bar(aes(fill=stroke), position = "fill", color = "black") + ggtitle(paste0("Stroke with Respect to ",y, " (Normalized)")) + xlab(y) + ylab("Count")
  
  plot(p1)
  plot(p2)
}

#Numeric
Num_eda <- function(x, y) {
  p1 <- ggplot(Stroke_clean, aes(x={{x}})) +
    geom_histogram(aes(fill=stroke), color = "black") +
    ggtitle(paste0("Stroke with Respect to ", y)) +
    xlab(y) + ylab("Count")

 p2 <- ggplot(Stroke_clean, aes(x={{x}})) +  
   geom_histogram(aes(fill=stroke), color = "black", position =      "fill") +
   ggtitle(paste0("Stroke with Respect to ", y)) +
   xlab(y) + ylab("Count")
 
 plot(p1)
 plot(p2)
  
}

```


### Categorical Variables
```{r}
Cat_eda(gender, "Gender")
Cat_eda(hypertension, "Hypertension")
Cat_eda(heart_disease, "Heart Disease")
Cat_eda(ever_married, "Ever Married")
Cat_eda(work_type, "Work Type")
Cat_eda(Residence_type, "Residence Type")
Cat_eda(smoking_status, "Smoking Status")
``` 

### Numeric variables
```{r}
Num_eda(age, "Age")
Num_eda(avg_glucose_level, "Avg. Glucose Level")
Num_eda(bmi, "BMI")
```

### Correlation Matrix
```{r}
plot_correlation(Stroke)
```

# Data Preparation for modelling

## Partition Data 
```{r}
#Partition Data
trainIndex <- createDataPartition(y=Stroke_clean$stroke, p=0.8, list = F, times = 1)

Stroke_tr <- Stroke_clean[trainIndex, ]
Stroke_test <- Stroke_clean[-trainIndex, ]
```

## Balance Data?

### Visualize Stroke Balance in Training 
```{r}
#Dual Axis
ggplot(Stroke_tr, aes(x=stroke)) + 
  geom_bar() +
  scale_y_continuous(
    name = "Count",
    sec.axis = sec_axis(~./nrow(Stroke_tr), name = "Proportion")
  ) + ggtitle("Training Data")
```

### Oversampling
```{r}
#Get count of yes in training
minority <- Stroke_tr %>% group_by(stroke) %>% tally() %>% filter(stroke =="Yes")

#Change this to change balance to desired yes proportion
increase_to <- 0.5

#Calculate resample amouunt
oversample_n <- (increase_to*nrow(Stroke_tr)-minority$n)/(1-increase_to)

#Resample
to_oversample <- which(Stroke_tr$stroke == "Yes")
our_oversample <- sample(x = to_oversample, size = oversample_n, replace = T)
our_oversample <- Stroke_tr[our_oversample, ]
Stroke_over <- rbind(Stroke_tr, our_oversample)

#Evaluate
ggplot(Stroke_over, aes(x=stroke)) + 
  geom_bar() +
  scale_y_continuous(
    name = "Count",
    sec.axis = sec_axis(~./nrow(Stroke_over), name = "Proportion")
  )  + ggtitle("Oversampled Data")
```


## Standardization
### Min-Max Standardization Function - Use standard.df() to create your own data set for model if you feel standardization is necessary.
```{r}
#Function to Standardize One Variable
standard.mm <- function(x){
  (x - min(x)) / (max(x) - min(x))
}

#Function to Standardize all Numeric Variables in Data Frame
standard.mm.df <- function(x){
  #Split Data
  tr_num <- x %>% select(where(is.numeric))
  tr_non <- x %>% select(!where(is.numeric))
  
  #Run Standardization Function Across Numeric
  tr_num_mm <- apply(X = tr_num, FUN = standard.mm, MARGIN = 2)
  
  #Recombine
  tr_mm <- cbind(tr_non, tr_num_mm)
}

```

### Z-Score Standardization
```{r}
#Z-Score Function
standard.z <- function(x){
  (x-mean(x))/sd(x)
}

#Function to Standardize all Numeric Variables in Data Frame
standard.z.df <- function(x){
  #Split Data
  tr_num <- x %>% select(where(is.numeric))
  tr_non <- x %>% select(!where(is.numeric))
  
  #Run Standardization Function Across Numeric
  tr_num_mm <- apply(X = tr_num, FUN = standard.z, MARGIN = 2)
  
  #Recombine
  tr_mm <- cbind(tr_non, tr_num_mm)
}

```

### Feature Selection
```{r}
# Run the boruta
library(Boruta)

boruta_out <- Boruta(stroke ~ ., data = Stroke_over_z, doTrace = 2)

boruta_sig <- getSelectedAttributes(boruta_out, withTentative = T)

print(boruta_sig)

imps <- attStats(boruta_out)
imps2 = imps[imps$decision != 'Rejected', c('meanImp', 'decision')]
imps2[order(-imps2$meanImp), ]

plot(boruta_out, cex.axis=.7, las=2, xlab="", main="Variable Importance")  

# All Variables were deemed important
```

# Modeling
## C5.0 - Andrew
```{r}
library(C50)
C5 <- C5.0(formula = stroke ~ . , data = Stroke_over, control = C5.0Control(minCases = 75))
```

```{r}
#Visualize the tree
plot(C5)
```

```{r}
#Create a data frame that includes the predictor variables of the records to classify.
X = Stroke_over %>% select(!stroke)
```

```{r}
#Obtain the classifications for each record in the data set. 
y_pred <- predict(object = C5, newdata = X)
```


## CART - Ben

###Install rpart and rpart.plot, run CART decision tree model:
```{r}
library(rpart)
library(rpart.plot)
cart01 <- rpart(formula = stroke ~ ., data = Stroke_over, method = "class")
rpart.plot(cart01)
```
###obtain the predicted responses:

```{r}
X = Stroke_over %>% select(!stroke)

Stroke_over_pred <- predict(object = cart01, newdata = X, type = "class")

```

###Create Confusion matrix for the training data set "Stroke_over" actual vs predicted results:

```{r}
Stroke_over$stroke_pred <- Stroke_over_pred
cart01_t1 <- table(Stroke_over$stroke, Stroke_over$stroke_pred)
row.names(cart01_t1) <- c("Actual: No", "Actual: Yes")
colnames(cart01_t1) <- c("Predicted: No", "Predicted: Yes")
cart01_t1 <- addmargins(A = cart01_t1, FUN = list(Total = sum), quiet = TRUE)
cart01_t1.df <- as.data.frame.matrix(cart01_t1)
cart01_t1.df

```
###Evaluate model performance on training data:

```{r}
#calculate evaluation metrics
precision_1 <- cart01_t1.df[2,2] / cart01_t1.df[3,2]
Accuracy_1 <- (cart01_t1.df[1,1] +cart01_t1.df[2,2])/cart01_t1.df[3,3]
error_rate_1 <- 1 - Accuracy_1
sensitivity_1 <- cart01_t1.df[2,2]/cart01_t1.df[1,3]
specificity_1 <- cart01_t1.df[1,1]/cart01_t1.df[1,3]
f1_1 <- 2*((precision_1 * specificity_1)/(precision_1+specificity_1))
f2_1 <- 5*((precision_1*specificity_1)/((4*precision_1)+specificity_1))
f0.5_1 <- 1.25*((precision_1 * specificity_1)/((0.25*precision_1)*specificity_1))
#create dataframe for evaluation metrics
eval.df1 <- data.frame(eval.measure = c("Accuracy", "error.rate", "sensitivity", "specificity", "precision", "f1", "f2", "f0.5"))
eval.df1$model.1 <- round(c(Accuracy_1, error_rate_1, sensitivity_1, specificity_1, precision_1, f1_1, f2_1, f0.5_1), 2)
eval.df1

```
###Now run the test data through the model and evaluate performance.

```{r}
#store variables to pass through model in dataframe:
X = stroke_test %>% select(!stroke)
#run test dataset through trained model:
Stroke_test_pred <- predict(object = cart01, newdata = X, type = "class")
#create confustion matrix dataframe:
Stroke_test$stroke_pred <- Stroke_test_pred
cart01_t2 <- table(Stroke_test$stroke, Stroke_test$stroke_pred)
row.names(cart01_t2) <- c("Actual: No", "Actual: Yes")
colnames(cart01_t2) <- c("Predicted: No", "Predicted: Yes")
cart01_t2 <- addmargins(A = cart01_t2, FUN = list(Total = sum), quiet = TRUE)
cart01_t2.df <- as.data.frame.matrix(cart01_t2)
cart01_t2.df
```
###Evaluate model performance on training data:

```{r}
#calculate evaluation metrics
precision_2 <- cart01_t2.df[2,2] / cart01_t2.df[3,2]
Accuracy_2 <- (cart01_t2.df[1,1] +cart01_t2.df[2,2])/cart01_t2.df[3,3]
error_rate_2 <- 1 - Accuracy_1
sensitivity_2 <- cart01_t2.df[2,2]/cart01_t2.df[1,3]
specificity_2 <- cart01_t2.df[1,1]/cart01_t2.df[1,3]
f1_2 <- 2*((precision_2 * specificity_2)/(precision_2+specificity_2))
f2_2 <- 5*((precision_2*specificity_2)/((4*precision_2)+specificity_2))
f0.5_2 <- 1.25*((precision_2 * specificity_2)/((0.25*precision_2)*specificity_2))
#create dataframe for evaluation metrics
eval.df2 <- data.frame(eval.measure = c("Accuracy", "error.rate", "sensitivity", "specificity", "precision", "f1", "f2", "f0.5"))
eval.df2$model.2 <- round(c(Accuracy_2, error_rate_2, sensitivity_2, specificity_2, precision_2, f1_2, f2_2, f0.5_2), 2)
eval.df2
```

## Logistic Regression - Ben

```{r}
#unbalanced
Stroke_tr_z_lr <- standard.z.df(Stroke_tr)
logreg_stroke <- glm(formula = stroke ~ ., data = Stroke_tr_z_lr, family = binomial)
summary(logreg_stroke)
#balanced
Stroke_tr_z_bal_lr <- standard.z.df(Stroke_over)
logreg01_stroke <- glm(formula = stroke ~ ., data = Stroke_tr_z_bal_lr, family = binomial)
summary(logreg01_stroke)
```
### Remove variables with a p-value < .05:

```{r}
head(Stroke_tr_z_bal_lr)
```

```{r}
Stroke_logreg_df <- subset(Stroke_tr_z_bal_lr, select = c("gender", "hypertension", "heart_disease", "smoking_status", "age", "avg_glucose_level", "stroke"))
logreg_stroke_subset <- glm(formula = stroke ~ ., data = Stroke_logreg_df, family = binomial)
summary(logreg_stroke_subset)
```
### Compare the logreg predictions to the training dataset target variables.  Covert the probabilites to binary outputs in a new column called 'pred' on the Stroke_logreg_df dataframe:

```{r}
# prediction
Stroke_logreg_df$pred_prob <- predict(object = logreg_stroke_subset, newdata = Stroke_logreg_df, type='response')
Stroke_logreg_df$pred <- (Stroke_logreg_df$pred_prob > 0.5)*1

# Change pred variables to y/n
Stroke_logreg_df$pred[Stroke_logreg_df$pred=="1"]<-"Yes"
Stroke_logreg_df$pred[Stroke_logreg_df$pred=="0"]<-"No"

# create contingency table of predicted vs. actual
logreg_t1 <- table(Stroke_logreg_df$stroke, Stroke_logreg_df$pred)
row.names(logreg_t1) <- c("Actual: No", "Actual: Yes")
colnames(logreg_t1) <- c("Predicted: No", "Predicted: Yes")
logreg_t1 <- addmargins(A = logreg_t1, FUN = list(Total = sum), quiet = TRUE)
logreg_t1.df <- as.data.frame.matrix(logreg_t1)
logreg_t1.df

```
### Evaluation metric for the logistic regression model

```{r}
#calculate evaluation metrics
precision_lr <- logreg_t1.df[2,2] / logreg_t1.df[3,2]
Accuracy_lr <- (logreg_t1.df[1,1] + logreg_t1.df[2,2])/logreg_t1.df[3,3]
error_rate_lr <- 1 - Accuracy_lr
sensitivity_lr <- logreg_t1.df[2,2]/logreg_t1.df[1,3]
specificity_lr <- logreg_t1.df[1,1]/logreg_t1.df[1,3]
f1_lr <- 2*((precision_lr * specificity_lr)/(precision_lr+specificity_lr))
f2_lr <- 5*((precision_lr*specificity_lr)/((4*precision_lr)+specificity_lr))
f0.5_lr <- 1.25*((precision_lr * specificity_lr)/((0.25*precision_lr)*specificity_lr))
#create dataframe for evaluation metrics
eval.dflr <- data.frame(eval.measure = c("Accuracy", "error.rate", "sensitivity", "specificity", "precision", "f1", "f2", "f0.5"))
eval.dflr$model.lr <- round(c(Accuracy_2, error_rate_2, sensitivity_2, specificity_2, precision_2, f1_2, f2_2, f0.5_2), 2)
eval.dflr
```


## Random Forest - Hunter
### Create Models
```{r}
rf_stroke <- caret::train(stroke~., method="rf", data = Stroke_tr, tuneLength = 5, trControl = trainControl(
  method = "cv", indexOut = train
))

rf_stroke

rf_stroke_bal <- caret::train(stroke~., method="rf", data = Stroke_over, tuneLength = 5, trControl = trainControl(
  method = "cv", indexOut = train
))

rf_stroke_bal
```
### Confusion Matrices
```{r}
confusionMatrix(data = predict(rf_stroke, Stroke_test), ref = Stroke_test$stroke, positive = "Yes")

confusionMatrix(data = predict(rf_stroke_bal, Stroke_test), ref = Stroke_test$stroke, positive = "Yes")
```



## Linear Regression - Andrew
```{r}
logreg01 <- glm(formula = stroke ~ ., data = Stroke_over, family = binomial)
summary(logreg01)
```

## Naive Bayes - Andrew
# Create the tables that will allow calculation of necessary probabilities 
# First table is the contingency table of "stroke" and "gender". The value 1 indicates "yes" while 0 indicates "no."

# Table Function
```{r}
#x = data set, y = non stroke variable
nb_table <- function(x, y) {
  gen <- table(x[,"stroke"], x[,y])
  colnames(gen) <- levels(x[,y])
  rownames(gen) <- c("stroke = Yes", "stroke = No")
  addmargins(A = gen, FUN = list(Total = sum), quiet = TRUE)
} 

#Example
nb_table(Stroke_over, "gender")
```

```{r}
gen <- table(Stroke_over$stroke, Stroke_over$gender)
colnames(gen) <- c("gender = Male", "gender = Female")
rownames(gen) <- c("stroke = 1", "stroke = 0")
addmargins(A = gen, FUN = list(Total = sum), quiet = TRUE)
```

# Second table is the contingency table of "stroke" and "hypertension". The value 1 indicates "yes" while 0 indicates "no."
```{r}
hyp <- table(Stroke_over$stroke, Stroke_over$hypertension)
colnames(hyp) <- c("hypertension = 1", "hyptertension = 0")
rownames(hyp) <- c("stroke = 1", "stroke = 0")
addmargins(A = hyp, FUN = list(Total = sum), quiet = TRUE)
```

# Third table is the contingency table of "stroke" and "heart disease". The value 1 indicates "yes" while 0 indicates "no."
```{r}
hd <- table(Stroke_over$stroke, Stroke_over$heart_disease)
colnames(hd) <- c("heart_disease = 1", "heart_disease = 0")
rownames(hd) <- c("stroke = 1", "stroke = 0")
addmargins(A = hd, FUN = list(Total = sum), quiet = TRUE)
```

# Fourth table is the contingency table of "stroke" and "ever married". 
```{r}
Ma <- table(Stroke_over$stroke, Stroke_over$ever_married)
colnames(Ma) <- c("ever_married = Yes", "ever_married = No")
rownames(Ma) <- c("stroke = 1", "stroke = 0")
addmargins(A = Ma, FUN = list(Total = sum), quiet = TRUE)
```

# Fifth table is the contingency table of "stroke" and "residence type".
```{r}
resd <- table(Stroke_over$stroke, Stroke_over$Residence_type)
colnames(resd) <- c("Residence_type = Urban", "Residence_type = Rural")
rownames(resd) <- c("stroke = 1", "stroke = 0")
addmargins(A = resd, FUN = list(Total = sum), quiet = TRUE)
```

# Sixth table is the contingency table of "stroke" and "smoking status".
```{r}
smoke <- table(Stroke_over$stroke, Stroke_over$smoking_status)
colnames(smoke) <- c("smoking_status = formerly smoked", "smoking_status = never smoked", "smoking_status = smokes", "smoking_status = Unknown")
rownames(smoke) <- c("stroke = 1", "stroke = 0")
addmargins(A = smoke, FUN = list(Total = sum), quiet = TRUE)
```

# Seventh table is the contingency table of "stroke" and "work type".
```{r}
work <- table(Stroke_over$stroke, Stroke_over$work_type)
colnames(work) <- c("work_type=children", "work_type=Govt_job", "work_type=Never_worked", "work_type=Private", "work_type=Self-employed")
rownames(work) <- c("stroke = 1", "stroke = 0")
addmargins(A = work, FUN = list(Total = sum), quiet = TRUE)
```

# Gridlines for each variable in association with "stroke".
```{r}
library(gridExtra)
```

# Graphs of "stroke" in association with "gender" and "hyptertension".

# Plot Function 
```{r}

nb_plot <- function(x, y){
  ggplot(x, aes(stroke)) + geom_bar(aes(fill=x[,y]), position = "fill") + ylab("Proportion") + labs(fill = y)
}

#Example 
grid.arrange(nb_plot(Stroke_over, "gender"), nb_plot(Stroke_over,"hypertension"), nrow = 1)
```

```{r}
plot1 <- ggplot(Stroke_over, aes(stroke)) + geom_bar(aes(fill=gender), position = "fill") + ylab("Proportion")
plot2 <- ggplot(Stroke_over, aes(stroke)) + geom_bar(aes(fill = hypertension), position = "fill") + ylab("Proportion")
grid.arrange(plot1, plot2, nrow = 1)
```

# Run the Naive Bayes estimator for "stroke" in association with "gender" and "hypertension".
```{r}
library(e1071)
nb01 <- naiveBayes(formula = stroke ~ gender + hypertension, data = Stroke_over)
```

# Graphs of "stroke" in association with "heart disease" and "ever married".
```{r}
plot3 <- ggplot(Stroke_over, aes(stroke)) + geom_bar(aes(fill=heart_disease), position = "fill") + ylab("Proportion")
plot4 <- ggplot(Stroke_over, aes(stroke)) + geom_bar(aes(fill=ever_married), position = "fill") + ylab("Proportion")
grid.arrange(plot3, plot4, nrow = 1)
```

# Run the Naive Bayes estimator for "stroke" in association with "heart disease" and "ever married".
```{r}
nb02 <- naiveBayes(formula = stroke ~ heart_disease + ever_married, data = Stroke_over)
```

# Graph of "stroke" in association with "Residence type".
```{r}
plot5 <- ggplot(Stroke_over, aes(stroke)) + geom_bar(aes(fill=Residence_type), position = "fill") + ylab("Proportion")
grid.arrange(plot5, nrow = 1)
```

# Run the Naive Bayes estimator for "stroke" in association with "Residence type".
```{r}
nb03 <- naiveBayes(formula = stroke ~ Residence_type, data = Stroke_over)
```

# Graph of "stroke" in association with "smoking status" and "work type".
```{r}
plot6 <- ggplot(Stroke_over, aes(stroke)) + geom_bar(aes(fill=smoking_status), position = "fill") + ylab("Proportion")
plot7 <- ggplot(Stroke_over, aes(stroke)) + geom_bar(aes(fill=work_type), position = "fill") + ylab("Proportion")
grid.arrange(plot6, plot7, nrow = 1)
```

# Run the Naive Bayes estimator for "stroke" in association with "smoking status" and "work type".
```{r}
nb04 <- naiveBayes(formula = stroke ~ smoking_status + work_type, data = Stroke_over)
```

## Association Rule - Ben




## Neural Network - Hunter

### Fitting Models
```{r}
#Unbalanced
train <- createFolds(Stroke_tr$stroke, k=10)

nnet_stroke <- caret::train(stroke ~ ., method = "nnet", data = Stroke_tr,
    tuneLength = 5,
    trControl = trainControl(
        method = "cv", indexOut = train),
  trace = FALSE)   
                     
                     

nnet_stroke$finalModel
plotnet(nnet_stroke$finalModel)

#Balanced

train <- createFolds(Stroke_over$stroke, k=10)

nnet_stroke_balanced <- caret::train(stroke ~ ., method = "nnet", data = Stroke_over,
    tuneLength = 5,
    trControl = trainControl(
        method = "cv", indexOut = train),
  trace = FALSE)   
   
nnet_stroke_balanced
plotnet(nnet_stroke_balanced$finalModel)

#Z-Score Standardized

Stroke_tr_z_nnet <- standard.z.df(Stroke_tr)

train <- createFolds(Stroke_tr_z_nnet$stroke, k=10)


nnet_stroke_z <- caret::train(stroke ~ ., method = "nnet", data = Stroke_tr_z_nnet,
    tuneLength = 5,
    trControl = trainControl(
        method = "cv", indexOut = train),
  trace = FALSE)   
   
nnet_stroke_z
plotnet(nnet_stroke_z$finalModel)

#Z-score standardized and balanced

Stroke_tr_z_bal <- standard.z.df(Stroke_over)

train <- createFolds(Stroke_tr_z_nnet$stroke, k=10)


nnet_stroke_z_bal <- caret::train(stroke ~ ., method = "nnet", data = Stroke_over,
    tuneLength = 5,
    trControl = trainControl(
        method = "cv", indexOut = train),
  trace = FALSE)   
   
nnet_stroke_z_bal
plotnet(nnet_stroke_z_bal$finalModel)
```

### Evaluate NN
```{r}
nnet_reg <- confusionMatrix(data = predict(nnet_stroke, Stroke_test), ref = Stroke_test$stroke, positive = "Yes")
nnet_reg

nnet_bal <- confusionMatrix(data = predict(nnet_stroke_balanced, Stroke_test), ref = Stroke_test$stroke, positive = "Yes")
nnet_bal

nnet_z <- confusionMatrix(data = predict(nnet_stroke_z, Stroke_test), ref = Stroke_test$stroke, positive = "Yes")
nnet_z

nnet_z_bal <- confusionMatrix(data = predict(nnet_stroke_z_bal, Stroke_test), ref = Stroke_test$stroke, positive = "Yes")
nnet_z_bal
```

# Model Evaluation
## Add Baseline?

## Model Comparison Data Frame
```{r}
Model = c("ANN Reg.", "ANN Bal.", "ANN Z", "ANN Z Bal.")
Accuracy = c(nnet_reg$overall[1], nnet_bal$overall[1], nnet_z$overall[1], nnet_z_bal$overall[1])

Model_comp <- data.frame(Model, Accuracy)
```

## Accuracy Graph
```{r}
ggplot(Model_comp, aes(x=Model, y=Accuracy)) + geom_bar(stat = "identity")
```
